<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">
    
    <meta property='og:title' content='Sophie Computer'/>
    <meta property='og:image' content='https://sophie.computer/papers/thumbnail.png'/>
    <meta property='og:description' content='Paper Log'/>
    <meta property='og:url' content='https://sophie.computer/papers/index.html'/>
    <meta property='og:image:width' content='1200' />
    <meta property='og:image:height' content='627' />
    <meta property="og:type" content='website'/>

    <title>SOPHIE COMPUTER: Papers</title>
    <link rel="stylesheet" href="/style-content.css">
    <link rel="icon" type="image/x-icon" href="media/star-blink.gif">
  </head>
  <body class="webpage">
    <script> 
      const query_string = window.location.search; 
      const url_params = new URLSearchParams(query_string); 
      if (!url_params.has('contentonly')) {
        window.location.replace("/index.html?redirect=/papers/index.html");
      }
    </script> 
    <div style="width: 100%; height: 100%;">
      <div class="main-content">
        <div class="main-section">
          <!-- <summary_text> -->
<p>This is where I log the papers I've read this year. My goal for 2026 is to read 300 papers. By the last time this document was last updated (<b>January 25, 2026</b>), I have read <b>10 papers</b> this year. I should have read <b>20 papers</b> by this time, meaning I am <b>10 papers behind schedule</b>.</p>
          <!-- </summary_text> -->
          <p><img src="cal.png" style="width: 100%;" alt="A monthly calendar depicting the following tabular data graphically."></p>
          <!-- <paper_table> -->
<table>
  <tr><td>1/19/26</td><td>The Landscape of GPU-Centric Communication</td><td><a href="https://arxiv.org/abs/2409.09874" target="_parent">Link</a></td><td>Ko√ß University, arXiv, 2024</td></tr>
  <tr><td>1/18/26</td><td>Hot Regions in SPEC CPU2017</td><td><a href="https://lca.ece.utexas.edu/pubs/qinzhe_iiswc.pdf" target="_parent">Link</a></td><td>UT Austin, IISWC, 2018</td></tr>
  <tr><td>1/12/26</td><td>A Scheduling Framework for Efficient MoE Inference on Edge GPU-NDP Systems</td><td><a href="https://arxiv.org/abs/2601.03992" target="_parent">Link</a></td><td>Nanjing University China, arXiv, 2026</td></tr>
  <tr><td>1/10/26</td><td>PyTorch FSDP: Experiences on Scaling Fully Sharded Data Parallel</td><td><a href="https://dl.acm.org/doi/10.14778/3611540.3611569" target="_parent">Link</a></td><td>Meta AI, Proceedings of the VLDB Endowment, 2023</td></tr>
  <tr><td>1/8/26</td><td>MSCCL++: Rethinking GPU Communication Abstractions for Cutting-edge AI Applications</td><td><a href="https://arxiv.org/abs/2504.09014" target="_parent">Link</a></td><td>Microsoft, arXiv, 2025</td></tr>
  <tr><td>1/8/26</td><td>Design Space Exploration of DMA based Finer-Grain Compute Communication Overlap</td><td><a href="https://arxiv.org/pdf/2512.10236" target="_parent">Link</a></td><td>UT Austin/AMD, arXiv, 2025</td></tr>
  <tr><td>1/7/26</td><td>GPGPU Power Modeling for Multi-Domain Voltage-Frequency Scaling</td><td><a href="https://ieeexplore.ieee.org/document/5714687" target="_parent">Link</a></td><td>UT Austin, IEEE Transactions on Computers, 2012</td></tr>
  <tr><td>1/3/26</td><td>Phase-Based Frequency Scaling for Energy-Efficient Heterogeneous Computing</td><td><a href="https://ieeexplore.ieee.org/document/11078489" target="_parent">Link</a></td><td>University of Salerno Italy, IPDPS, 2025</td></tr>
  <tr><td>1/2/26</td><td>Runtime Power Monitoring in High-End Processors: Methodology and Empirical Data</td><td><a href="https://ieeexplore.ieee.org/document/1253186" target="_parent">Link</a></td><td>Princeton, MICRO, 2003, 12 pages</td></tr>
  <tr><td>1/1/26</td><td>GPGPU Power Modeling for Multi-Domain Voltage-Frequency Scaling</td><td><a href="https://ieeexplore.ieee.org/document/8327055" target="_parent">Link</a></td><td>2018, 12 pages</td></tr>
  <tr><td>12/31/25</td><td>Designing Spatial Architectures for Sparse Attention: STAR Accelerator via Cross-Stage Tiling</td><td><a href="https://arxiv.org/abs/2512.20198" target="_parent">Link</a></td><td>2025, 15 pages</td></tr>
  <tr><td>12/31/25</td><td>Optimal Software Pipelining and Warp Specialization for Tensor Core GPUs</td><td><a href="https://arxiv.org/abs/2512.18134" target="_parent">Link</a></td><td>2025, 15 pages</td></tr>
  <tr><td>12/27/25</td><td>Optimizing Distributed ML Communication with Fused Computation-Collective Operations</td><td><a href="https://dl.acm.org/doi/10.1109/SC41406.2024.00094?__cf_chl_tk=JiIcf3Jk6bXO95CvnjFpZXgo3VwgkYWQvxjVkOlOmDA-1766844635-1.0.1.1-hUvnYbaShXnBOVqGvBSTvMqF3LO6raVWm0zAmm0etjc" target="_parent">Link</a></td><td>2024, 17 pages</td></tr>
  <tr><td>12/26/25</td><td>Defect graph neural networks for materials discovery in high-temperature clean-energy applications</td><td><a href="https://www.nature.com/articles/s43588-023-00495-2" target="_parent">Link</a></td><td>2023, 12 pages</td></tr>
  <tr><td>12/24/25</td><td>Power Stabilization for AI Training Datacenters</td><td><a href="https://arxiv.org/pdf/2508.14318" target="_parent">Link</a></td><td>2025, 10 pages</td></tr>
  <tr><td>12/23/25</td><td>Advancing Cloud Computing Capabilities on gem5 by Implementing the RISC-V Hypervisor Extension</td><td><a href="https://carrv.github.io/2024/papers/CARRV_2024_paper_3.pdf" target="_parent">Link</a></td><td>2024, 8 pages</td></tr>
</table>
          <!-- </paper_table> --> 
        </div> 
      </div>
        
      <!-- <last_updated_text> --> 
<div class="last-updated">
  <p class="last-updated-text">
    Last updated: January 25, 2026 at 20:15 UTC.
  </p>
</div>

      <!-- </last_updated_text> --> 
    </div>
  </body>
</html>
